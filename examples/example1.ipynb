{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sitting-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from patternly.detection import AnomalyDetection\n",
    "from patternly._utils import UnionFind, DirectedGraph\n",
    "from zedsuite.zutil import Llk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unsigned-silicon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating distance matrix...\n",
      "Clustering distance matrix...\n",
      "Generating cluster PFSA 1/5...\n",
      "Generating cluster PFSA 2/5...\n",
      "Generating cluster PFSA 3/5...\n",
      "Generating cluster PFSA 4/5...\n",
      "Generating cluster PFSA 5/5...\n",
      "Attempting to reduce clusters...\n",
      "Reduced clusters from 5 to 4.\n",
      "Clustering distance matrix...\n",
      "Generating cluster PFSA 1/4...\n",
      "Generating cluster PFSA 2/4...\n",
      "Generating cluster PFSA 3/4...\n",
      "Generating cluster PFSA 4/4...\n",
      "Attempting to reduce clusters...\n",
      "Reduced clusters from 4 to 2.\n",
      "Clustering distance matrix...\n",
      "Generating cluster PFSA 1/2...\n",
      "Generating cluster PFSA 2/2...\n",
      "Attempting to reduce clusters...\n",
      "Calculating cluster PFSA means and stds...\n",
      "Model fit.\n",
      "CPU times: user 8.69 s, sys: 24.4 ms, total: 8.72 s\n",
      "Wall time: 3.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Prepare data\n",
    "quantized_time_series = pd.read_csv(\n",
    "    \"./data/example1.dat\", sep=\" \", header=None, low_memory=False\n",
    ").dropna(how=\"all\", axis=1)\n",
    "\n",
    "# Fit detection pipeline to training data\n",
    "pipeline = AnomalyDetection(anomaly_sensitivity=2, n_clusters=5, reduce_clusters=True, quantize=False, eps=0.1, verbose=True)\n",
    "pipeline = pipeline.fit(quantized_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "vulnerable-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cluster_likelihoods = np.empty(shape=(pipeline.n_clusters, pipeline.n_clusters), dtype=np.float32)\n",
    "all_ranked_likelihoods = np.empty(shape=(pipeline.n_clusters, pipeline.n_clusters), dtype=np.int32)\n",
    "\n",
    "for i in range(pipeline.n_clusters):\n",
    "    cluster_llks = []\n",
    "    for pfsafile in pipeline.cluster_PFSA_files:\n",
    "        cluster_data = pipeline.quantized_data[pipeline.quantized_data[\"cluster\"] == i].drop(columns=[\"cluster\"], axis=1)\n",
    "        cluster_llks.append(np.asarray(Llk(data=cluster_data, pfsafile=pfsafile).run(), dtype=np.float32))\n",
    "        \n",
    "    # which cluster PFSA each sequence most likely maps back to\n",
    "    closest_matches = np.argmin(cluster_llks, axis=0)\n",
    "    # the likelihoods of the sequences generated by the current PFSA mapping back to each cluster PFSA \n",
    "    cluster_likelihoods = np.count_nonzero(\n",
    "        (closest_matches.reshape(-1, 1) == np.arange(pipeline.n_clusters).reshape(1, -1)), \n",
    "        axis=0\n",
    "#     ) / pipeline.quantized_data[pipeline.quantized_data[\"cluster\"] == i].shape[0]\n",
    "    ) / pipeline.cluster_counts[i]\n",
    "    # list of cluster PFSAs sorted in descending order of likelihood\n",
    "    ranked_likelihoods = np.argsort(cluster_likelihoods)[::-1]\n",
    "    all_cluster_likelihoods[i] = cluster_likelihoods\n",
    "    all_ranked_likelihoods[i] = ranked_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "published-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15       0.4        0.35       0.1        0.        ]\n",
      " [0.8        0.13333334 0.06666667 0.         0.        ]\n",
      " [1.         0.         0.         0.         0.        ]\n",
      " [0.         0.5714286  0.14285715 0.2857143  0.        ]\n",
      " [0.         0.         0.         0.         1.        ]]\n",
      "[[1 2 0 3 4]\n",
      " [0 1 2 4 3]\n",
      " [0 4 3 2 1]\n",
      " [1 3 2 4 0]\n",
      " [4 3 2 1 0]]\n",
      "[20, 15, 8, 7, 5]\n"
     ]
    }
   ],
   "source": [
    "print(all_cluster_likelihoods)\n",
    "print(all_ranked_likelihoods)\n",
    "print(pipeline.cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "average-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(set, {0: {0, 1, 2, 3}, 1: {0, 1}, 2: {0}, 3: {1, 2, 3}, 4: {4}})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(len(all_cluster_likelihoods)):\n",
    "#     if all_ranked_likelihoods[i][0] != i:\n",
    "#         all_cluster_likelihoods[all_ranked_likelihoods[i][0]][i] += 0.1\n",
    "# print(all_cluster_likelihoods)\n",
    "graph = DirectedGraph(5)\n",
    "graph.from_matrix(all_cluster_likelihoods, threshold=0)\n",
    "print(graph.find_scc())\n",
    "len(set(graph.low_links))\n",
    "graph.graph\n",
    "graph = DirectedGraph(5)\n",
    "graph.from_matrix(all_cluster_likelihoods >= 0.1)\n",
    "graph.graph\n",
    "# graph.find_scc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "short-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 3 4]\n",
      "[0 0 2 3 4]\n",
      "[0 0 0 3 4]\n",
      "[0 0 0 0 4]\n",
      "[0 0 0 0 4]\n",
      "\n",
      "[0 0 0 0 4]: 2 components\n",
      "{0, 4}\n"
     ]
    }
   ],
   "source": [
    "graph = UnionFind(pipeline.n_clusters)\n",
    "for i in range(pipeline.n_clusters):\n",
    "    best_match = all_ranked_likelihoods[i][0]\n",
    "    second_best_match = all_ranked_likelihoods[i][1]\n",
    "    if best_match != i:\n",
    "        graph.union(i, best_match, ranks=(all_cluster_likelihoods[i]+all_cluster_likelihoods[best_match]))\n",
    "    if second_best_match != i and all_cluster_likelihoods[i][second_best_match] > 2 * (1 / pipeline.n_clusters):\n",
    "        graph.union(i, second_best_match, ranks=(all_cluster_likelihoods[i]+all_cluster_likelihoods[second_best_match]))\n",
    "    print(graph.roots)\n",
    "    \n",
    "print(f\"\\n{graph.compress_all().roots}: {graph.n_components} components\")\n",
    "print(set(graph.roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sealed-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "CPU times: user 143 ms, sys: 1.01 ms, total: 144 ms\n",
      "Wall time: 144 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictions = pd.DataFrame(pipeline.predict())\n",
    "anomalies = predictions[predictions[0] == True]\n",
    "print(anomalies.shape[0])\n",
    "anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "scientific-setup",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 PFSA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"zed_temp/clean_5faaa72c-7984-4921-bef4-035397a51851.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 PFSA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"zed_temp/clean_86518268-346d-4fbb-8610-3579d765ef00.png\" width=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 PFSA:\n",
      "    %ANN_ERR: 11.1166\n",
      "    %MRG_EPS: 0.1\n",
      "    %SYN_STR: \n",
      "    %SYM_FRQ: 0.42765 0.57235 \n",
      "    %PITILDE: size(2)\n",
      "    #PITILDE\n",
      "    0.599018 0.400982 \n",
      "    0.299581 0.700419 \n",
      "    %CONNX: size(2)\n",
      "    #CONNX\n",
      "    0.599018 0.400982 \n",
      "    0.299581 0.7004\n",
      "\n",
      "Cluster 1 PFSA:\n",
      "    %ANN_ERR: 11.1159\n",
      "    %MRG_EPS: 0.1\n",
      "    %SYN_STR: \n",
      "    %SYM_FRQ: 0.427375 0.572625 \n",
      "    %PITILDE: size(2)\n",
      "    #PITILDE\n",
      "    0.603012 0.396988 \n",
      "    0.296256 0.703744 \n",
      "    %CONNX: size(2)\n",
      "    #CONNX\n",
      "    0.603012 0.396988 \n",
      "    0.296256 0.7037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML\n",
    "for i, file in enumerate(pipeline.cluster_PFSA_pngs):\n",
    "    print(f\"Cluster {i} PFSA\")\n",
    "    display(Image(url=f\"{file}.png\", width=300))\n",
    "    \n",
    "pipeline.print_PFSAs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
