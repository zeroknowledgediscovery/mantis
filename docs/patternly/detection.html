<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>patternly.detection API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#66bb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>patternly.detection</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
from zedsuite.zutil import Llk, Lsmash
from zedsuite.genesess import GenESeSS
from zedsuite.quantizer import Quantizer
from patternly._utils import RANDOM_NAME, os_remove


class AnomalyDetection:
    &#34;&#34;&#34; Tool for anomaly detection &#34;&#34;&#34;
    def __init__(
        self,
        *,
        anomaly_sensitivity=1,
        clustering_alg=KMeans(),
        quantize=True,
        quantize_type=&#34;complex&#34;,
        eps=0.1,
        verbose=False
    ) -&gt; None:
        &#34;&#34;&#34;
        Args:

            anomaly_sensitivity (float, optional): how many standard deviations above the mean
                                                   llk to consider an anomaly (Default = 1)\n
            cluster_alg (sklearn.cluster, optional): clustering algorithm to use
                                                     (Default = KMeans())\n
            quantize (bool, optional): whether to quantize the data (Default = True)\n
            quantize_type (str, optional): type of quantization to use (&#34;complex&#34; or &#34;simple&#34;)
                                           (Default = &#34;complex&#34;)\n
            eps (float, optional): epsilon parameter for finding PFSAs (Default = 0.1)\n
            verbose (bool, optional): whether to print verbose output (Default = False)\n

        &#34;&#34;&#34;

        self.anomaly_sensitivity = anomaly_sensitivity
        self.clustering_alg = clustering_alg
        self.quantize = quantize
        self.quantize_type = quantize_type
        self.eps = eps
        self.verbose = verbose
        self.temp_dir = &#34;zed_temp&#34;

        # values calculated in self.fit()
        self._fitted = False               # whether model has been fit
        self.quantizer = None              # quantizer used for quantizing data
        self.data_file = &#34;&#34;                # file path of original data
        self.dist_matrix = pd.DataFrame()  # calculated by lsmash, used for clustering
        self.clusters = []                 # list of cluster labels
        self.cluster_files = []            # list of file paths to clusters
        self.dot_files = []                # list of file paths to PFSA dot files
        self.cluster_PFSAs = []            # list of file paths to cluster PFSAs
        self.cluster_PFSAs_info = []       # list of dicts of cluster PFSAs info for printing
        self.PFSA_llk_means = []           # list of mean llk for each cluster
        self.PFSA_llk_stds = []            # list of std of llk for each cluster

        # can be accessed after calling self.predict()
        self.curr_cluster_llk_vec = None
        self.closest_match = None


    def fit(self, X, y=None):
        &#34;&#34;&#34; Fit an anomaly detection model

        Args:

            X (pd.DataFrame or str): time series data to be fit
            y (pd.Series, optional): labels for X only provided for sklearn standard
                                     (Default = None)

        Returns:

            self
        &#34;&#34;&#34;
        X_quantized = self.__quantize(X)
        self.__calculate_dist_matrix(X if type(X) is str else X_quantized)
        self.__calculate_cluster_labels()
        self.__write_cluster_files(X_quantized)
        self.__calculate_cluster_PFSAs()
        self.__calculate_PFSA_stats()
        self._fitted = True
        return self


    def predict(self, X=None, *, clean=True):
        &#34;&#34;&#34; Predict whether a time series sequence is anomalous

        Args:

            X (pd.DataFrame or pd.Series or str, optional): time series data to find anomalies, if None then
                                                            predicts on original data (Default = None)
            clean (bool, optional): whether to remove temp files (Default = True)

        Returns:

            bool or list[bool]: True if time series is an anomaly, False otherwise
                                output shape depends on input
        &#34;&#34;&#34;
        seqfile = &#34;&#34;
        num_predictions = 0
        # commonly want to find anomalies in original data
        if X is None:
            seqfile = self.data_file
            num_predictions = len(self.clusters)
        else:
            # if type(X) is str and not self.quantize:
            #     seqfile = X
            # else:
            is_series = type(X) is pd.Series
            seqfile = RANDOM_NAME(path=self.temp_dir, clean=True)
            X_quantized = self.__quantize(X)
            X_quantized.to_csv(
                seqfile,
                sep=&#34; &#34;,
                line_terminator=(&#34; &#34; if is_series else &#34;\n&#34;),
                index=False,
                header=False
            )

            if is_series:
                num_predictions = 1
                # remove trailing space because it affects llk calculation
                with open(seqfile, &#34;r+&#34;) as f:
                    line = next(f).rstrip()
                    f.seek(0)
                    f.write(line + &#34;\n&#34;)
            else:
                num_predictions = X_quantized.shape[0]

        cluster_llk_vec = np.empty([len(self.cluster_PFSAs), num_predictions], dtype=np.float64)
        anomaly_vec = np.zeros(num_predictions, dtype=np.int8)
        for i in range(len(self.cluster_PFSAs)):
            curr_llks = Llk(seqfile=seqfile, pfsafile=self.cluster_PFSAs[i]).run()
            cluster_llk_vec[i] = curr_llks
            # classify llk as anomaly if greater than X standard deviations above the mean
            upper_bound = self.PFSA_llk_means[i] + (self.PFSA_llk_stds[i] * self.anomaly_sensitivity)
            for j, llk in enumerate(curr_llks):
                anomaly_vec[j] += 1 if llk &gt; upper_bound else 0
        self.curr_cluster_llk_vec = cluster_llk_vec
        self.closest_match = np.argmin(cluster_llk_vec, axis=0)

        # consider to be anomaly if all llks above specified upper bound
        predictions = [x == len(self.cluster_PFSAs) for x in anomaly_vec]

        if len(predictions) == 1:
            predictions = predictions[0]

        if seqfile != self.data_file and clean:
            os_remove(seqfile)

        return predictions


    def print_PFSAs(self):
        &#34;&#34;&#34; Print PFSAs found for each cluster &#34;&#34;&#34;
        properties = [&#34;%ANN_ERR&#34;, &#34;%MRG_EPS&#34;, &#34;%SYN_STR&#34;, &#34;%SYM_FRQ&#34;, &#34;%PITILDE&#34;, &#34;%CONNX&#34;]
        for i in range(len(self.cluster_PFSAs_info)):
            print(f&#34;Cluster {i} PFSA:&#34;)
            for prop in properties:
                print(f&#34;{prop}: {self.cluster_PFSAs_info[i][prop]}&#34;)
            if i != len(self.cluster_PFSAs_info) - 1:
                print(&#34;\n&#34;)


    def __quantize(self, X):
        &#34;&#34;&#34; Quantize the data into finite alphabet &#34;&#34;&#34;
        if not self.quantize or self.quantize_type is None:
            if type(X) is str:
                return pd.read_csv(X, sep=&#34; &#34;, header=None, low_memory=False).dropna(how=&#34;all&#34;, axis=1)
            else:
                return X.copy()
        if self.verbose:
            print(&#34;Quantizing...&#34;)
        # Quantizer() expects a DataFrame
        if type(X) is pd.Series:
            X = X.copy().to_frame().reset_index(drop=True).T
        if self.quantize_type == &#34;simple&#34;:
            # basic differentiation
            X = X.astype(float).diff(axis=1).fillna(0)
            return X.apply(lambda row : row.apply(lambda n : 1 if n &gt; 0 else 0), axis=1)
        elif self.quantize_type == &#34;complex&#34;:
            # use cythonized quantizer binary
            if not self._fitted:
                self.quantizer = Quantizer(n_quantizations=1, epsilon=-1)
                self.quantizer.fit(X)
            return pd.concat([quantized for quantized in self.quantizer.transform(X)], axis=1)
        else:
            raise ValueError(f&#34;Unknown quantize type: {self.quantize_type}. Choose \&#34;simple\&#34; or \&#34;complex\&#34;.&#34;)


    def __calculate_dist_matrix(self, X):
        &#34;&#34;&#34; Calculate distance matrix using lsmash &#34;&#34;&#34;
        if self.verbose:
            print(&#34;Calculating distance matrix...&#34;)
        # don&#39;t create file if it already exists i.e. X is a file path
        if type(X) is str and not self.quantize:
            self.data_file = X
        else:
            self.data_file = RANDOM_NAME(path=self.temp_dir)
            X.to_csv(self.data_file, sep=&#34; &#34;, index=False, header=False)

        self.dist_matrix = pd.DataFrame(Lsmash(seqfile=self.data_file, data_type=&#34;symbolic&#34;, sae=False).run()).round(8)


    def __calculate_cluster_labels(self):
        &#34;&#34;&#34; Cluster distance matrix &#34;&#34;&#34;
        if self.verbose:
            print(&#34;Clustering distance matrix...&#34;)
        self.clusters = self.clustering_alg.fit(self.dist_matrix).labels_


    def __write_cluster_files(self, X):
        &#34;&#34;&#34; Write cluster time series data to files &#34;&#34;&#34;
        n_clusters = len(set(self.clusters)) - (1 if -1 in self.clusters else 0)
        X[&#34;cluster&#34;] = self.clusters
        cluster_files = []
        if (n_clusters == 1):
            cluster_files.append(self.data_file)
        else:
            for i in range(n_clusters):
                if self.verbose:
                    print(f&#34;Writing cluster {i + 1}/{n_clusters} to file...&#34;)
                cluster_files.append(RANDOM_NAME(path=self.temp_dir))
                X[X[&#34;cluster&#34;] == i] \
                    .drop(&#34;cluster&#34;, axis=1) \
                    .to_csv(cluster_files[i], sep=&#34; &#34;, header=False, index=False, float_format=&#34;%g&#34;)
        self.cluster_files = cluster_files


    def __calculate_cluster_PFSAs(self):
        &#34;&#34;&#34; Infer PFSAs from clusters using genESeSS &#34;&#34;&#34;
        cluster_PFSAs = []
        dot_files = []
        for i, cluster_file in enumerate(self.cluster_files):
            if self.verbose:
                print(f&#34;Generating cluster PFSA {i + 1}/{len(self.cluster_files)}...&#34;)
            PFSA_file = RANDOM_NAME(path=self.temp_dir)
            cluster_PFSAs.append(PFSA_file)
            dot_file = RANDOM_NAME(path=self.temp_dir)
            dot_files.append(dot_file)
            alg = GenESeSS(
                datafile=cluster_file,
                outfile=PFSA_file,
                data_type=&#34;symbolic&#34;,
                data_dir=&#34;row&#34;,
                force=True,
                eps=self.eps,
                dot=dot_file,
            )
            alg.run()
            PFSA_info = {}
            PFSA_info[&#34;%ANN_ERR&#34;] = alg.inference_error
            PFSA_info[&#34;%MRG_EPS&#34;] = alg.epsilon_used
            PFSA_info[&#34;%SYN_STR&#34;] = alg.synchronizing_string_found
            PFSA_info[&#34;%SYM_FRQ&#34;] = alg.symbol_frequency
            PFSA_info[&#34;%PITILDE&#34;] = alg.probability_morph_matrix
            PFSA_info[&#34;%CONNX&#34;] = alg.connectivity_matrix
            self.cluster_PFSAs_info.append(PFSA_info)

        self.cluster_PFSAs = cluster_PFSAs
        self.dot_files = dot_files


    def __calculate_PFSA_stats(self):
        &#34;&#34;&#34; Calculate the means and standard deviations of llks for each PFSA
            to later determine if a sequence is an anomaly &#34;&#34;&#34;
        if self.verbose:
            print(&#34;Calculating cluster PFSA means and stds...&#34;)
        PFSA_llk_means = []
        PFSA_llk_stds = []
        for i in range(len(self.cluster_PFSAs)):
            llks = np.array(Llk(seqfile=self.cluster_files[i], pfsafile=self.cluster_PFSAs[i]).run())
            PFSA_llk_means.append(np.mean(llks))
            PFSA_llk_stds.append(np.std(llks))
        self.PFSA_llk_means, self.PFSA_llk_stds = PFSA_llk_means, PFSA_llk_stds</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="patternly.detection.AnomalyDetection"><code class="flex name class">
<span>class <span class="ident">AnomalyDetection</span></span>
<span>(</span><span>*, anomaly_sensitivity=1, clustering_alg=KMeans(), quantize=True, quantize_type='complex', eps=0.1, verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Tool for anomaly detection </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>anomaly_sensitivity</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>how many standard deviations above the mean
llk to consider an anomaly (Default = 1)</dd>
<dt><strong><code>cluster_alg</code></strong> :&ensp;<code>sklearn.cluster</code>, optional</dt>
<dd>clustering algorithm to use
(Default = KMeans())</dd>
<dt><strong><code>quantize</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>whether to quantize the data (Default = True)</dd>
<dt><strong><code>quantize_type</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>type of quantization to use ("complex" or "simple")
(Default = "complex")</dd>
<dt><strong><code>eps</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>epsilon parameter for finding PFSAs (Default = 0.1)</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>whether to print verbose output (Default = False)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AnomalyDetection:
    &#34;&#34;&#34; Tool for anomaly detection &#34;&#34;&#34;
    def __init__(
        self,
        *,
        anomaly_sensitivity=1,
        clustering_alg=KMeans(),
        quantize=True,
        quantize_type=&#34;complex&#34;,
        eps=0.1,
        verbose=False
    ) -&gt; None:
        &#34;&#34;&#34;
        Args:

            anomaly_sensitivity (float, optional): how many standard deviations above the mean
                                                   llk to consider an anomaly (Default = 1)\n
            cluster_alg (sklearn.cluster, optional): clustering algorithm to use
                                                     (Default = KMeans())\n
            quantize (bool, optional): whether to quantize the data (Default = True)\n
            quantize_type (str, optional): type of quantization to use (&#34;complex&#34; or &#34;simple&#34;)
                                           (Default = &#34;complex&#34;)\n
            eps (float, optional): epsilon parameter for finding PFSAs (Default = 0.1)\n
            verbose (bool, optional): whether to print verbose output (Default = False)\n

        &#34;&#34;&#34;

        self.anomaly_sensitivity = anomaly_sensitivity
        self.clustering_alg = clustering_alg
        self.quantize = quantize
        self.quantize_type = quantize_type
        self.eps = eps
        self.verbose = verbose
        self.temp_dir = &#34;zed_temp&#34;

        # values calculated in self.fit()
        self._fitted = False               # whether model has been fit
        self.quantizer = None              # quantizer used for quantizing data
        self.data_file = &#34;&#34;                # file path of original data
        self.dist_matrix = pd.DataFrame()  # calculated by lsmash, used for clustering
        self.clusters = []                 # list of cluster labels
        self.cluster_files = []            # list of file paths to clusters
        self.dot_files = []                # list of file paths to PFSA dot files
        self.cluster_PFSAs = []            # list of file paths to cluster PFSAs
        self.cluster_PFSAs_info = []       # list of dicts of cluster PFSAs info for printing
        self.PFSA_llk_means = []           # list of mean llk for each cluster
        self.PFSA_llk_stds = []            # list of std of llk for each cluster

        # can be accessed after calling self.predict()
        self.curr_cluster_llk_vec = None
        self.closest_match = None


    def fit(self, X, y=None):
        &#34;&#34;&#34; Fit an anomaly detection model

        Args:

            X (pd.DataFrame or str): time series data to be fit
            y (pd.Series, optional): labels for X only provided for sklearn standard
                                     (Default = None)

        Returns:

            self
        &#34;&#34;&#34;
        X_quantized = self.__quantize(X)
        self.__calculate_dist_matrix(X if type(X) is str else X_quantized)
        self.__calculate_cluster_labels()
        self.__write_cluster_files(X_quantized)
        self.__calculate_cluster_PFSAs()
        self.__calculate_PFSA_stats()
        self._fitted = True
        return self


    def predict(self, X=None, *, clean=True):
        &#34;&#34;&#34; Predict whether a time series sequence is anomalous

        Args:

            X (pd.DataFrame or pd.Series or str, optional): time series data to find anomalies, if None then
                                                            predicts on original data (Default = None)
            clean (bool, optional): whether to remove temp files (Default = True)

        Returns:

            bool or list[bool]: True if time series is an anomaly, False otherwise
                                output shape depends on input
        &#34;&#34;&#34;
        seqfile = &#34;&#34;
        num_predictions = 0
        # commonly want to find anomalies in original data
        if X is None:
            seqfile = self.data_file
            num_predictions = len(self.clusters)
        else:
            # if type(X) is str and not self.quantize:
            #     seqfile = X
            # else:
            is_series = type(X) is pd.Series
            seqfile = RANDOM_NAME(path=self.temp_dir, clean=True)
            X_quantized = self.__quantize(X)
            X_quantized.to_csv(
                seqfile,
                sep=&#34; &#34;,
                line_terminator=(&#34; &#34; if is_series else &#34;\n&#34;),
                index=False,
                header=False
            )

            if is_series:
                num_predictions = 1
                # remove trailing space because it affects llk calculation
                with open(seqfile, &#34;r+&#34;) as f:
                    line = next(f).rstrip()
                    f.seek(0)
                    f.write(line + &#34;\n&#34;)
            else:
                num_predictions = X_quantized.shape[0]

        cluster_llk_vec = np.empty([len(self.cluster_PFSAs), num_predictions], dtype=np.float64)
        anomaly_vec = np.zeros(num_predictions, dtype=np.int8)
        for i in range(len(self.cluster_PFSAs)):
            curr_llks = Llk(seqfile=seqfile, pfsafile=self.cluster_PFSAs[i]).run()
            cluster_llk_vec[i] = curr_llks
            # classify llk as anomaly if greater than X standard deviations above the mean
            upper_bound = self.PFSA_llk_means[i] + (self.PFSA_llk_stds[i] * self.anomaly_sensitivity)
            for j, llk in enumerate(curr_llks):
                anomaly_vec[j] += 1 if llk &gt; upper_bound else 0
        self.curr_cluster_llk_vec = cluster_llk_vec
        self.closest_match = np.argmin(cluster_llk_vec, axis=0)

        # consider to be anomaly if all llks above specified upper bound
        predictions = [x == len(self.cluster_PFSAs) for x in anomaly_vec]

        if len(predictions) == 1:
            predictions = predictions[0]

        if seqfile != self.data_file and clean:
            os_remove(seqfile)

        return predictions


    def print_PFSAs(self):
        &#34;&#34;&#34; Print PFSAs found for each cluster &#34;&#34;&#34;
        properties = [&#34;%ANN_ERR&#34;, &#34;%MRG_EPS&#34;, &#34;%SYN_STR&#34;, &#34;%SYM_FRQ&#34;, &#34;%PITILDE&#34;, &#34;%CONNX&#34;]
        for i in range(len(self.cluster_PFSAs_info)):
            print(f&#34;Cluster {i} PFSA:&#34;)
            for prop in properties:
                print(f&#34;{prop}: {self.cluster_PFSAs_info[i][prop]}&#34;)
            if i != len(self.cluster_PFSAs_info) - 1:
                print(&#34;\n&#34;)


    def __quantize(self, X):
        &#34;&#34;&#34; Quantize the data into finite alphabet &#34;&#34;&#34;
        if not self.quantize or self.quantize_type is None:
            if type(X) is str:
                return pd.read_csv(X, sep=&#34; &#34;, header=None, low_memory=False).dropna(how=&#34;all&#34;, axis=1)
            else:
                return X.copy()
        if self.verbose:
            print(&#34;Quantizing...&#34;)
        # Quantizer() expects a DataFrame
        if type(X) is pd.Series:
            X = X.copy().to_frame().reset_index(drop=True).T
        if self.quantize_type == &#34;simple&#34;:
            # basic differentiation
            X = X.astype(float).diff(axis=1).fillna(0)
            return X.apply(lambda row : row.apply(lambda n : 1 if n &gt; 0 else 0), axis=1)
        elif self.quantize_type == &#34;complex&#34;:
            # use cythonized quantizer binary
            if not self._fitted:
                self.quantizer = Quantizer(n_quantizations=1, epsilon=-1)
                self.quantizer.fit(X)
            return pd.concat([quantized for quantized in self.quantizer.transform(X)], axis=1)
        else:
            raise ValueError(f&#34;Unknown quantize type: {self.quantize_type}. Choose \&#34;simple\&#34; or \&#34;complex\&#34;.&#34;)


    def __calculate_dist_matrix(self, X):
        &#34;&#34;&#34; Calculate distance matrix using lsmash &#34;&#34;&#34;
        if self.verbose:
            print(&#34;Calculating distance matrix...&#34;)
        # don&#39;t create file if it already exists i.e. X is a file path
        if type(X) is str and not self.quantize:
            self.data_file = X
        else:
            self.data_file = RANDOM_NAME(path=self.temp_dir)
            X.to_csv(self.data_file, sep=&#34; &#34;, index=False, header=False)

        self.dist_matrix = pd.DataFrame(Lsmash(seqfile=self.data_file, data_type=&#34;symbolic&#34;, sae=False).run()).round(8)


    def __calculate_cluster_labels(self):
        &#34;&#34;&#34; Cluster distance matrix &#34;&#34;&#34;
        if self.verbose:
            print(&#34;Clustering distance matrix...&#34;)
        self.clusters = self.clustering_alg.fit(self.dist_matrix).labels_


    def __write_cluster_files(self, X):
        &#34;&#34;&#34; Write cluster time series data to files &#34;&#34;&#34;
        n_clusters = len(set(self.clusters)) - (1 if -1 in self.clusters else 0)
        X[&#34;cluster&#34;] = self.clusters
        cluster_files = []
        if (n_clusters == 1):
            cluster_files.append(self.data_file)
        else:
            for i in range(n_clusters):
                if self.verbose:
                    print(f&#34;Writing cluster {i + 1}/{n_clusters} to file...&#34;)
                cluster_files.append(RANDOM_NAME(path=self.temp_dir))
                X[X[&#34;cluster&#34;] == i] \
                    .drop(&#34;cluster&#34;, axis=1) \
                    .to_csv(cluster_files[i], sep=&#34; &#34;, header=False, index=False, float_format=&#34;%g&#34;)
        self.cluster_files = cluster_files


    def __calculate_cluster_PFSAs(self):
        &#34;&#34;&#34; Infer PFSAs from clusters using genESeSS &#34;&#34;&#34;
        cluster_PFSAs = []
        dot_files = []
        for i, cluster_file in enumerate(self.cluster_files):
            if self.verbose:
                print(f&#34;Generating cluster PFSA {i + 1}/{len(self.cluster_files)}...&#34;)
            PFSA_file = RANDOM_NAME(path=self.temp_dir)
            cluster_PFSAs.append(PFSA_file)
            dot_file = RANDOM_NAME(path=self.temp_dir)
            dot_files.append(dot_file)
            alg = GenESeSS(
                datafile=cluster_file,
                outfile=PFSA_file,
                data_type=&#34;symbolic&#34;,
                data_dir=&#34;row&#34;,
                force=True,
                eps=self.eps,
                dot=dot_file,
            )
            alg.run()
            PFSA_info = {}
            PFSA_info[&#34;%ANN_ERR&#34;] = alg.inference_error
            PFSA_info[&#34;%MRG_EPS&#34;] = alg.epsilon_used
            PFSA_info[&#34;%SYN_STR&#34;] = alg.synchronizing_string_found
            PFSA_info[&#34;%SYM_FRQ&#34;] = alg.symbol_frequency
            PFSA_info[&#34;%PITILDE&#34;] = alg.probability_morph_matrix
            PFSA_info[&#34;%CONNX&#34;] = alg.connectivity_matrix
            self.cluster_PFSAs_info.append(PFSA_info)

        self.cluster_PFSAs = cluster_PFSAs
        self.dot_files = dot_files


    def __calculate_PFSA_stats(self):
        &#34;&#34;&#34; Calculate the means and standard deviations of llks for each PFSA
            to later determine if a sequence is an anomaly &#34;&#34;&#34;
        if self.verbose:
            print(&#34;Calculating cluster PFSA means and stds...&#34;)
        PFSA_llk_means = []
        PFSA_llk_stds = []
        for i in range(len(self.cluster_PFSAs)):
            llks = np.array(Llk(seqfile=self.cluster_files[i], pfsafile=self.cluster_PFSAs[i]).run())
            PFSA_llk_means.append(np.mean(llks))
            PFSA_llk_stds.append(np.std(llks))
        self.PFSA_llk_means, self.PFSA_llk_stds = PFSA_llk_means, PFSA_llk_stds</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="patternly.detection.AnomalyDetection.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, X, y=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Fit an anomaly detection model</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>str</code></dt>
<dd>time series data to be fit</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pd.Series</code>, optional</dt>
<dd>labels for X only provided for sklearn standard
(Default = None)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>self</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self, X, y=None):
    &#34;&#34;&#34; Fit an anomaly detection model

    Args:

        X (pd.DataFrame or str): time series data to be fit
        y (pd.Series, optional): labels for X only provided for sklearn standard
                                 (Default = None)

    Returns:

        self
    &#34;&#34;&#34;
    X_quantized = self.__quantize(X)
    self.__calculate_dist_matrix(X if type(X) is str else X_quantized)
    self.__calculate_cluster_labels()
    self.__write_cluster_files(X_quantized)
    self.__calculate_cluster_PFSAs()
    self.__calculate_PFSA_stats()
    self._fitted = True
    return self</code></pre>
</details>
</dd>
<dt id="patternly.detection.AnomalyDetection.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, X=None, *, clean=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Predict whether a time series sequence is anomalous</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>pd.Series</code> or <code>str</code>, optional</dt>
<dd>time series data to find anomalies, if None then
predicts on original data (Default = None)</dd>
<dt><strong><code>clean</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>whether to remove temp files (Default = True)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code> or <code>list[bool]</code></dt>
<dd>True if time series is an anomaly, False otherwise
output shape depends on input</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self, X=None, *, clean=True):
    &#34;&#34;&#34; Predict whether a time series sequence is anomalous

    Args:

        X (pd.DataFrame or pd.Series or str, optional): time series data to find anomalies, if None then
                                                        predicts on original data (Default = None)
        clean (bool, optional): whether to remove temp files (Default = True)

    Returns:

        bool or list[bool]: True if time series is an anomaly, False otherwise
                            output shape depends on input
    &#34;&#34;&#34;
    seqfile = &#34;&#34;
    num_predictions = 0
    # commonly want to find anomalies in original data
    if X is None:
        seqfile = self.data_file
        num_predictions = len(self.clusters)
    else:
        # if type(X) is str and not self.quantize:
        #     seqfile = X
        # else:
        is_series = type(X) is pd.Series
        seqfile = RANDOM_NAME(path=self.temp_dir, clean=True)
        X_quantized = self.__quantize(X)
        X_quantized.to_csv(
            seqfile,
            sep=&#34; &#34;,
            line_terminator=(&#34; &#34; if is_series else &#34;\n&#34;),
            index=False,
            header=False
        )

        if is_series:
            num_predictions = 1
            # remove trailing space because it affects llk calculation
            with open(seqfile, &#34;r+&#34;) as f:
                line = next(f).rstrip()
                f.seek(0)
                f.write(line + &#34;\n&#34;)
        else:
            num_predictions = X_quantized.shape[0]

    cluster_llk_vec = np.empty([len(self.cluster_PFSAs), num_predictions], dtype=np.float64)
    anomaly_vec = np.zeros(num_predictions, dtype=np.int8)
    for i in range(len(self.cluster_PFSAs)):
        curr_llks = Llk(seqfile=seqfile, pfsafile=self.cluster_PFSAs[i]).run()
        cluster_llk_vec[i] = curr_llks
        # classify llk as anomaly if greater than X standard deviations above the mean
        upper_bound = self.PFSA_llk_means[i] + (self.PFSA_llk_stds[i] * self.anomaly_sensitivity)
        for j, llk in enumerate(curr_llks):
            anomaly_vec[j] += 1 if llk &gt; upper_bound else 0
    self.curr_cluster_llk_vec = cluster_llk_vec
    self.closest_match = np.argmin(cluster_llk_vec, axis=0)

    # consider to be anomaly if all llks above specified upper bound
    predictions = [x == len(self.cluster_PFSAs) for x in anomaly_vec]

    if len(predictions) == 1:
        predictions = predictions[0]

    if seqfile != self.data_file and clean:
        os_remove(seqfile)

    return predictions</code></pre>
</details>
</dd>
<dt id="patternly.detection.AnomalyDetection.print_PFSAs"><code class="name flex">
<span>def <span class="ident">print_PFSAs</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Print PFSAs found for each cluster</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print_PFSAs(self):
    &#34;&#34;&#34; Print PFSAs found for each cluster &#34;&#34;&#34;
    properties = [&#34;%ANN_ERR&#34;, &#34;%MRG_EPS&#34;, &#34;%SYN_STR&#34;, &#34;%SYM_FRQ&#34;, &#34;%PITILDE&#34;, &#34;%CONNX&#34;]
    for i in range(len(self.cluster_PFSAs_info)):
        print(f&#34;Cluster {i} PFSA:&#34;)
        for prop in properties:
            print(f&#34;{prop}: {self.cluster_PFSAs_info[i][prop]}&#34;)
        if i != len(self.cluster_PFSAs_info) - 1:
            print(&#34;\n&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="patternly_dark.png" alt="drawing" style="width:400px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="patternly" href="index.html">patternly</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="patternly.detection.AnomalyDetection" href="#patternly.detection.AnomalyDetection">AnomalyDetection</a></code></h4>
<ul class="">
<li><code><a title="patternly.detection.AnomalyDetection.fit" href="#patternly.detection.AnomalyDetection.fit">fit</a></code></li>
<li><code><a title="patternly.detection.AnomalyDetection.predict" href="#patternly.detection.AnomalyDetection.predict">predict</a></code></li>
<li><code><a title="patternly.detection.AnomalyDetection.print_PFSAs" href="#patternly.detection.AnomalyDetection.print_PFSAs">print_PFSAs</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Author: Drew Vlasnik and Ishanu Chattopadhyay <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery, University of Chicago</a>. Email: ishanu@uchicago.edu
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>